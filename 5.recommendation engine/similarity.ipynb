{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "推荐引擎，需要量化相似度：\n",
    "    欧式距离\n",
    "    皮尔逊系数\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欧氏距离\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def euclidean_score(dataset, user1, user2):\n",
    "    if user1 not in dataset:\n",
    "        raise TypeError('User '+user1+' not in dataset')\n",
    "    if user2 not in dataset:\n",
    "        raise TypeErrorr('User '+user2+' not in dataset')\n",
    "    \n",
    "    # 为了计算分数，需要提取两个用户均评估过分的电影\n",
    "    rated_by_both = {}\n",
    "    for item in dataset[user1]:\n",
    "        for item in dataset[user2]:\n",
    "            rated_by_both[item] = 1\n",
    "    \n",
    "    # 如果users之间没有共同评过的电影，说明没有相似度\n",
    "    if not rated_by_both:\n",
    "        return 0\n",
    "    \n",
    "    # 对于共同评分，计算平方和的平方根，并将该值归一化\n",
    "    squared_differences = []\n",
    "    for item in dataset[user1]:\n",
    "        for item in dataset[user2]:\n",
    "            squared_differences.append(np.square(dataset[user1][item] - dataset[user2][item]))\n",
    "    return 1 / (1 + np.sqrt(np.sum(squared_differences)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 皮尔逊相关系数\n",
    "def pearson_score(dataset, user1, user2):\n",
    "    if user1 not in dataset:\n",
    "        raise TypeError('User '+user1+' not in dataset')\n",
    "    if user2 not in dataset:\n",
    "        raise TypeErrorr('User '+user2+' not in dataset')\n",
    "    \n",
    "    # 为了计算分数，需要提取两个用户均评估过分的电影\n",
    "    rated_by_both = {}\n",
    "    for item in dataset[user1]:\n",
    "        for item in dataset[user2]:\n",
    "            rated_by_both[item] = 1\n",
    "            \n",
    "    num_ratings = len(rated_by_both)\n",
    "    if not num_ratings :\n",
    "        num_ratings == 0\n",
    "        \n",
    "    # 如果users之间没有共同评过的电影，说明没有相似度\n",
    "    if not rated_by_both:\n",
    "        return 0\n",
    "    \n",
    "    # 计算相同评分电影的平方值之和\n",
    "    user1_sum = np.sum([dataset[user1][item] for item in rated_by_both])\n",
    "    user2_sum = np.sum([dataset[user2][item] for item in rated_by_both])\n",
    "    \n",
    "    # 计算所有相同评分电影的评分的平方和\n",
    "    user1_squared_sum = np.sum([np.square(dataset[user1][item]) for item in rated_by_both])\n",
    "    user2_squared_sum = np.sum([np.square(dataset[user2][item]) for item in rated_by_both])\n",
    "    \n",
    "    # 计算数据集的乘积之和\n",
    "    product_sum = np.sum([dataset[user1][item] * dataset[user2][item] for item in rated_by_both])\n",
    "    \n",
    "    # 计算皮尔逊相关度\n",
    "    Sxy = product_sum - (user1_sum * user2_sum / num_ratings)\n",
    "    Sxx = user1_squared_sum - np.square(user1_sum) / num_ratings\n",
    "    Syy = user2_squared_sum - np.square(user2_sum) / num_ratings\n",
    "    \n",
    "    if Sxx * Syy == 0:\n",
    "        return 0\n",
    "    \n",
    "    return Sxy / np.sqrt(Sxx * Syy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "No. 0  :  John Carson  ->  {'Inception': 2.5, 'Pulp Fiction': 3.5, 'Anger Management': 3.0, 'Fracture': 3.5, 'Serendipity': 2.5, 'Jerry Maguire': 3.0}\n",
      "No. 1  :  Michelle Peterson  ->  {'Inception': 3.0, 'Pulp Fiction': 3.5, 'Anger Management': 1.5, 'Fracture': 5.0, 'Jerry Maguire': 3.0, 'Serendipity': 3.5}\n",
      "No. 2  :  William Reynolds  ->  {'Inception': 2.5, 'Pulp Fiction': 3.0, 'Fracture': 3.5, 'Jerry Maguire': 4.0}\n",
      "No. 3  :  Jillian Hobart  ->  {'Pulp Fiction': 3.5, 'Anger Management': 3.0, 'Jerry Maguire': 4.5, 'Fracture': 4.0, 'Serendipity': 2.5}\n",
      "No. 4  :  Melissa Jones  ->  {'Inception': 3.0, 'Pulp Fiction': 4.0, 'Anger Management': 2.0, 'Fracture': 3.0, 'Jerry Maguire': 3.0, 'Serendipity': 2.0}\n",
      "\n",
      "Euclidean score:  0.14548268842493628\n",
      "\n",
      "Pearson score:  0.39605901719066977\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "input_file = 'movie_ratings.json'\n",
    "with open(input_file,'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "print(type(data))\n",
    "i = 0\n",
    "for key,val in data.items():\n",
    "    if i < 5:\n",
    "        print(\"No.\",i,' : ',key, ' -> ',val)\n",
    "        i += 1\n",
    "           \n",
    "user1 = 'John Carson'\n",
    "user2 = 'Michelle Peterson'\n",
    "\n",
    "print('\\nEuclidean score: ',euclidean_score(data,user1,user2))\n",
    "print('\\nPearson score: ',pearson_score(data, user1, user2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Users similar to John Carson:\n",
      "\n",
      "Scores : [['Michelle Peterson' '0.39605901719066977']\n",
      " ['William Reynolds' '0.40451991747794525']\n",
      " ['Jillian Hobart' '0.5669467095138396']\n",
      " ['Melissa Jones' '0.5940885257860044']\n",
      " ['Alex Roberts' '0.7470178808339965']]\n",
      "\n",
      "Scores_sorted:  [0 1 2 3 4]\n",
      "\n",
      "Scored_sorted_dec:  [5 4 3 2 1]\n",
      "\n",
      "Top_k : [5 4 3]\n",
      "User\t\tSimilarity score\n",
      "\n",
      "Michael Henry \t\t 0.99\n",
      "Alex Roberts \t\t 0.75\n",
      "Melissa Jones \t\t 0.59\n"
     ]
    }
   ],
   "source": [
    "# 构建推荐引擎中，一个非常重要的任务就是寻找相似的用户，\n",
    "# 即为某位用户生成的推荐信息可以同时推荐给与其相似的用户\n",
    "def find_similar_users(dataset, user, num_users):\n",
    "    if user not in dataset:\n",
    "        raise TypeError(\"User \" + user + \"not in dataset\")\n",
    "    \n",
    "    # 计算所有user的Pearson相关度\n",
    "    scores = np.array([[x, pearson_score(dataset, user, x)] for x in dataset if user != x])\n",
    "    print(\"Scores :\", scores[:5])\n",
    "    # sorted\n",
    "    scores_sorted = np.argsort(scores[:, 1])\n",
    "    scored_sorted_dec = scores_sorted[::-1]\n",
    "    print(\"\\nScores_sorted: \",scores_sorted[:5])\n",
    "    print(\"\\nScored_sorted_dec: \",scored_sorted_dec[:5])\n",
    "    \n",
    "    top_k = scored_sorted_dec[:num_users]\n",
    "    print(\"\\nTop_k :\", top_k)\n",
    "    return scores[top_k]\n",
    "\n",
    "data_file = 'movie_ratings.json'\n",
    "with open(data_file,'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "    \n",
    "user = 'John Carson'\n",
    "print(\"\\nUsers similar to \"+user+':\\n')\n",
    "similar_users = find_similar_users(data, user, 3)\n",
    "print(\"User\\t\\tSimilarity score\\n\")\n",
    "for item in similar_users:\n",
    "    print(item[0],'\\t\\t',round(float(item[1]),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for Michael Henry:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Inception'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b0e6d4681ba6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[1;32min\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nRecommendations for \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0muser\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mmovies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovie\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. '\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mmovie\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-b0e6d4681ba6>\u001b[0m in \u001b[0;36mgenerate_recommendations\u001b[1;34m(dataset, user)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0msimilarity_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpearson_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msimilarity_score\u001b[0m \u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-2848a0e95862>\u001b[0m in \u001b[0;36mpearson_score\u001b[1;34m(dataset, user1, user2)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# 计算相同评分电影的平方值之和\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0muser1_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrated_by_both\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0muser2_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrated_by_both\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-2848a0e95862>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# 计算相同评分电影的平方值之和\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0muser1_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrated_by_both\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0muser2_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrated_by_both\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Inception'"
     ]
    }
   ],
   "source": [
    "# 生成电影推荐\n",
    "def generate_recommendations(dataset, user):\n",
    "    if user not in dataset:\n",
    "        raise TypeError(user + \"not in dataset\")\n",
    "    \n",
    "    total_scores = {}\n",
    "    similarity_sums = {}\n",
    "    \n",
    "    for u in dataset:\n",
    "        if u == user:\n",
    "            continue\n",
    "        else:\n",
    "            similarity_score = pearson_score(dataset, user, u)\n",
    "        \n",
    "        if similarity_score <=0 :\n",
    "            continue\n",
    "    \n",
    "        for item in [x for x in dataset[u] if x not in dataset[user] or dataset[user][x] == 0]:\n",
    "            total_scores.update({item:dataset[u][item] * similarity_score})\n",
    "            similarity_sums.update({item: similarity_score})\n",
    "    \n",
    "    if not total_scores:\n",
    "        return [\"No recommendations possible\"]\n",
    "    \n",
    "    # 生成一个电影评分标准化列表\n",
    "    movie_ranks = np.array([[total/similarity_sums[item], item] for item, total in total_scores.items()])\n",
    "    # 根据第一列对Pearson相关系数进行降序排列\n",
    "    movie_ranks = movie_ranks[np.argsort(movie_ranks[:, 0])[::-1]]\n",
    "    \n",
    "    # recommendations\n",
    "    recommendations = [movie for _, movie in movie_ranks]\n",
    "    return recommedations\n",
    "\n",
    "data_file = 'movie_ratings.json'\n",
    "with open(data_file,'r') as f:\n",
    "    data = json.loads(f.read())\n",
    "    \n",
    "users = ['Michael Henry', 'John Carson']\n",
    "for user in users:\n",
    "    print(\"\\nRecommendations for \"+user+\":\")\n",
    "    movies = generate_recommendations(data, user)\n",
    "    for i, movie in enumerate(movies):\n",
    "        print(str(i+1) + '. '+ movie)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
