{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### /* 1.1 preprocessing data */ ###\n",
    "\n",
    "# Original Preparation\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "data = np.array([[3,-1.5,2,-5.4],[0,4,-0.3,2.1],[1,3.3,-1.9,-4.3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean =  [ 5.55111512e-17 -1.11022302e-16 -7.40148683e-17 -7.40148683e-17]\n",
      "Std deviation =  [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Mean removel 以使0-中心化\n",
    "data_standardized = preprocessing.scale(data)\n",
    "print(\"\\nMean = \",data_standardized.mean(axis=0))\n",
    "print(\"Std deviation = \",data_standardized.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min Max scaled data = \n",
      " [[1.         0.         1.         0.        ]\n",
      " [0.         1.         0.41025641 1.        ]\n",
      " [0.33333333 0.87272727 0.         0.14666667]]\n"
     ]
    }
   ],
   "source": [
    "# Scaling ：可以指定扩展特征值的波动区间\n",
    "data_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "data_scaled = data_scaler.fit_transform(data)\n",
    "print(\"\\nMin Max scaled data = \\n\",data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1 normalized data = \n",
      " [[ 0.25210084 -0.12605042  0.16806723 -0.45378151]\n",
      " [ 0.          0.625      -0.046875    0.328125  ]\n",
      " [ 0.0952381   0.31428571 -0.18095238 -0.40952381]]\n"
     ]
    }
   ],
   "source": [
    "# Normalization 标准/正则化\n",
    "data_normalized = preprocessing.normalize(data, norm='l1')  # L1正则化\n",
    "print(\"\\nL1 normalized data = \\n\",data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binarized data = \n",
      " [[1. 0. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Binarization 布尔二值化\n",
    "data_binarized = preprocessing.Binarizer(threshold=1.4).transform(data)\n",
    "print(\"\\nBinarized data = \\n\",data_binarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data : \n",
      " [[ 0  2  1 12]\n",
      " [ 1  3  5  3]\n",
      " [ 2  3  2 12]\n",
      " [ 1  2  4  3]]\n",
      "\n",
      "Encoder vecter : \n",
      " [[0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding : 统计n-维数据集中每个feature的唯一特征值个数(设k)，并将特征值由小到大排列，\n",
    "# 再对该特征值执行k-维0/1编码，只有一个位=1，其他位=0\n",
    "\n",
    "encoder_data = np.array([[0,2,1,12],[1,3,5,3],[2,3,2,12],[1,2,4,3]])\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit(encoder_data)\n",
    "encoded_vector = encoder.transform([[2,3,4,3]]).toarray()\n",
    "print(\"Original Data : \\n\",encoder_data)\n",
    "print(\"\\nEncoder vecter : \\n\",encoded_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class mapping:\n",
      "\n",
      "audi --> 0\n",
      "bmw --> 1\n",
      "ford --> 2\n",
      "toyota --> 3\n",
      "\n",
      "encode labels :  [0, 2, 0, 3, 2, 1]\n",
      "\n",
      "decode labels :  ['ford', 'bmw', 'audi', 'toyota', 'bmw']\n"
     ]
    }
   ],
   "source": [
    "### /* 1.2 Label Encoding /* ###\n",
    "from sklearn import preprocessing as skpp\n",
    "label_encoder = skpp.LabelEncoder() # it knows how to understand word labels,去重并排序\n",
    "\n",
    "# create labels\n",
    "input_classes = ['audi','ford','audi','toyota','ford','bmw']\n",
    "\n",
    "# encode labels 1\n",
    "label_encoder.fit(input_classes)\n",
    "print(\"\\nClass mapping:\\n\")\n",
    "for i,item in enumerate(label_encoder.classes_):\n",
    "    print(item,'-->',i)\n",
    "    \n",
    "\n",
    "# encode labels 2\n",
    "print(\"\\nencode labels : \",list(label_encoder.transform(input_classes)))\n",
    "\n",
    "# decode numeric labels back to words\n",
    "encoded_labels = [2,1,0,3,1]\n",
    "print(\"\\ndecode labels : \",list(label_encoder.inverse_transform(encoded_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
